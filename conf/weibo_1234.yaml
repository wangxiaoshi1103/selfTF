#Hyper Params
batch_size: 64
device: cuda
lr: 0.001
num_epochs: 100
n_workers: 0
model: tf_transformer  #模型选择
loader: base
is_bert: 1
is_static: 1
tower: add

# Dataset
ds_name: weibo
#train_samples: 114326
train_samples: 80000
#train_samples: 400
#test_samples: 1937
#test_samples: 3000
test_samples: 1500 
#val_samples: 1937
#val_samples: 3000
val_samples: 1500
input_size: 26
output_size: 1
total_time_steps: 60
num_encoder_steps: 50
bert_categoricals:
- topicName
- topicType
- introductId

static_input_loc:
- 23
- 24
- 25
input_obs_loc:
- 0
known_categorical_inputs:
- 0
- 1
- 2
known_regular_inputs:
- 1
- 2
- 3
- 4
- 5
- 6
- 7
- 8
- 9
- 10
- 11
- 12
- 13
- 14
- 15
- 16
- 17
- 18
- 19
- 20
- 21
- 22
category_counts:
- 10000
- 100
- 10000


# Model Temporal Fusion Transformer
quantiles:
- 0.1
- 0.5
- 0.9
batch_first: true
early_stopping_patience: 5
hidden_layer_size: 160
stack_size: 1
dropout_rate: 0.1
max_gradient_norm: 0.01
num_heads: 4
bert_output_size: 64

# Model Transformer
d_model: 64
q: 16
v: 16
h: 4
N: 2
attention_size: 0
dropout: 0.1
pe: original
chunk_mode: None
d_input: 5
d_output: 3
